# -*- coding: utf-8 -*-
"""Traffic model  .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10c5I15OuD8UogRbgfsITeGJtDiF1Wd8E
"""

from google.colab import drive
import os

# Mount Google Drive to access datasets
drive.mount('/content/drive')

# Change to your dataset directory
os.chdir('/content/drive/MyDrive/Colab Notebooks/Traffic dataset')



import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Image dimensions
img_height, img_width = 64, 64

# Data generators for training and validation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset',
    target_size=(img_height, img_width),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset',
    target_size=(img_height, img_width),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

import matplotlib.pyplot as plt # Import the pyplot module from matplotlib
from PIL import Image

# Define a list of image paths
image_paths = [
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road0.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road1.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road2.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road3.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road4.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road5.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road6.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road7.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road8.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road9.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road10.png',
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images/road11.png',
    # Add more paths as needed
]

# Plot images
plt.figure(figsize=(15, 15))
for i, path in enumerate(image_paths):
    img = Image.open(path)
    plt.subplot(5, 5, i + 1)
    plt.imshow(img)
    plt.axis('off')
plt.show()

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(43, activation='softmax')  # Assuming 43 classes of traffic signs
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score


# Image dimensions
img_height, img_width = 64, 64

# Data generators for training and validation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

# Make sure the directory path is correct and contains 43 subdirectories for classes
train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset',  # Verify this path
    target_size=(img_height, img_width),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset',  # Verify this path
    target_size=(img_height, img_width),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# Check the number of classes reported by the generator
num_classes = train_generator.num_classes
print("Number of classes found:", num_classes)

# Adjust the final layer of your model if necessary
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Flatten(), # Flatten the output for classification
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(num_classes, activation='softmax')  # Use the correct number of classes
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy', # Use categorical_crossentropy for classification
    metrics=['accuracy']
)

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    epochs=10
)
# Get true labels and predictions from the validation generator
y_true = validation_generator.classes
y_pred = model.predict(validation_generator)
y_pred = np.argmax(y_pred, axis=1) # Convert predictions to class labels

# Check if there are any classes to calculate metrics for
if num_classes > 1:
    # Compute Precision, Recall, F1-Score
    precision = precision_score(y_true, y_pred, average=None,zero_division=0) * 100
    recall = recall_score(y_true, y_pred, average=None,zero_division=0) * 100
    f1 = f1_score(y_true, y_pred, average=None,zero_division=0) * 100
    # Calculate overall accuracy
    accuracy = accuracy_score(y_true, y_pred) * 100
    print(f"Overall Accuracy: {accuracy:.2f}%")

    # Print metrics for each class
    for i, class_name in enumerate(validation_generator.class_indices): # Use validation_generator
        print(f"Class {class_name}: Precision = {precision[i]:.2f}%, Recall = {recall[i]:.2f}%, F1-Score = {f1[i]:.2f}%")
else:
    print("Warning: Only one class detected. Cannot calculate precision, recall, and F1-score.")

val_loss, val_acc = model.evaluate(validation_generator)
print(f"Validation Accuracy: {val_acc*100:.2f}%")

import numpy as np
from tensorflow.keras.preprocessing import image
import os

# Directory containing images
image_dir = '/content/drive/MyDrive/Colab Notebooks/Traffic dataset/images'

for filename in os.listdir(image_dir):
    if filename.endswith(".jpg") or filename.endswith(".png"):  # Check for image file extensions
        img_path = os.path.join(image_dir, filename)

        # Load and preprocess the image
        img = image.load_img(img_path, target_size=(img_height, img_width))
        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)

        # Make the prediction
        prediction = model.predict(img_array)
        predicted_class = np.argmax(prediction, axis=1)
        print(f"Image: {filename}, Predicted class: {predicted_class}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Image dimensions
img_height, img_width = 64, 64

# Data generators for training and validation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

# Make sure the directory path is correct and contains 43 subdirectories for classes
train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset',  # Verify this path
    target_size=(img_height, img_width),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/Traffic dataset',  # Verify this path
    target_size=(img_height, img_width),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# Check the number of classes reported by the generator
num_classes = train_generator.num_classes
print("Number of classes found:", num_classes)

# Adjust the final layer of your model if necessary
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Flatten(), # Flatten the output for classification
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(num_classes, activation='softmax')  # Use the correct number of classes
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy', # Use categorical_crossentropy for classification
    metrics=['accuracy']
)

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    epochs=10
)

# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'])
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'])
plt.show()


# Evaluate the model on the validation set
val_loss, val_acc = model.evaluate(validation_generator)
print(f"Validation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_acc*100:.2f}%")

# Get

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Load a sample dataset
data = load_iris()
X, y = data.data, data.target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train a classifier
classifier = RandomForestClassifier()
classifier.fit(X_train, y_train)

# Predict on the test set
y_pred = classifier.predict(X_test)

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data.target_names)
disp.plot(cmap=plt.cm.Blues)
plt.show()